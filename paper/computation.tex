\section{Computation} \label{sec:computation}
Users are more conscientious of their data now. However, they still desire
functional technology. In light of Facebook using personalized identifying
information (PII) (ostensibly used for two-factor identification) for
advertising~\cite{venkatadri1investigating} as well as previous and never-ending
leaks of personal information~\cite{fung_2017, granville_2018} more users are
aware of the hazards of giving third-parties PII.

More businesses make use of cloud computing services as well which brings up a
new host of issues, including whether these computations are done correctly, and
how much company data must be given to these services to get the job done. 

In this section we analyze the techniques developed to allow for secure
computation without providing private information and verifiable computation
through proofs of computation with no knowledge.

\subsection{Secure Computation} \label{ssec:secureComputation}
The problem of secure computation is often motivated by two entities
(individuals or more commonly companies) wishing to compute some function
$f(\cdot)$ on their combined data without having to directly share information.
This task can be completed by utilizing a trusted third party to collect data
from both parties, compute the function, and report the results. However, such a
scenario may be just as undesirable or impossible (e.g. two hospitals with
private patient data). Other recent work~\cite{scaife2018oniondns} attempts to
leverage the Tor network as a DNS routing system.

Nonetheless, the entities wish to answer some question on the union of their
data. Previous work analyzes the typical use case and threat model of such
situations~\cite{yao1982protocols, lindell2005secure}. Solutions to this problem
often leverage clever uses of encryption and obfuscations in order to obscure
information from separate parties. As such these protocols are tasked with
proving their correctness and security. 

In both correctness and security a protocol is judged by its relationship to an
analogous problem in the ``Ideal world''~\cite{lindell2005secure}. The Ideal
world is one in which a trusted third party (as above) exists, is willing and
capable of doing the computation on the union of data sets in a private way.
Often proofs of security work by showing that any adversary in the ``real
world'' model can modify their attack in polynomial time to be an attack in the
ideal world, as such attacks (on the protocol, not on data security itself) are
infeasible in the ideal world, the attack in the real world must also be secure.

While some work has been done towards generalized protocols for secure
computation, most recent work focuses on specific tasks that must be done
privately~\cite{bogetoft2009secure,miers2013zerocoin,parno2013pinocchio}. One
previous work~\cite{bogetoft2009secure} demonstrates the capability of secure
multiparty computation by creating a functioning auction among Danish beet
farmers. 

This work motivates the need for private auctions by the desire of beet farmers
to sell their beet contracts to other farmers (and informing the seller of the
contract) without having to leak financial information that could affect future
contract negotiations. Each farmer needs to announce (privately) their desired
bid (whether to buy or sell, and for how much at which quantities), and based on
these announcements the system needs to decide which contracts transfer to which
bidders.

This is achieved by using Shamir secret sharing~\cite{shamir1979share}, which
encodes data as points on a polynomial. After a secret has been encoded as a
point (usually in a field $\mathbb{F}$), say $x$, a polynomial, $f$, of degree
$t$, the number of representatives needed to reconstruct the secret, is created
such that $f(0)= x$. Shares of $x$ can be shared among the participants in the
form of evaluations of $f$, namely $f(1), f(2),\ldots, f(t+1)$. As $t+1$ points
are necessary to construct a polynomial of degree $t$, separately the secret has
been shared amongst people, but together the secret can be recovered.

The scenario above requires a trusted third party to construct the polynomial
$f$, and thus needs to know the secret $x$. This can be circumvented (as it is
in~\cite{bogetoft2009secure}) by leveraging symmetric encryption simple, public
polynomials. In~\cite{bogetoft2009secure} three non-colluding servers are used
along with keyed pseudo random function, $F$, and public functions $f_i$ such
that $f_i(0) = 1, f_i(i) = 0$ for $i=1,2,3$. Then clients can announce their
secret $x_j$ as:
\[
    y_j = F_{K_1}(j) + F_{K_2}(j) + F_{K_3}(j) + x_j \mod p
\]
The $i$th server knows all keys, except $K_i$ allowing it to compute it share of
the polynomial as:
\[
    y_j - F_{K_1}(j)f_1(i) - F_{K_2}(j)f_2(i) - F_{K_3}(j)f_3(i)
\]
Note that server $i$ cannot compute $F_{K_i}(j)$ but $f_i(i) = 0$ so that term
is negated in their computation, allowing them to complete it.

Together they have created the polynomial $g_j = F_{K_1}(j)f_1 - F_{K_2}(j)f_2
- F_{K_3}f_3$ to share private values between the three servers.

With the data effectively split between servers, the servers can perform local
computation on their shares (adding sell and buy values) to determine a fair
market price.

\subsection{Verifiable Computation}\label{ssec:verifiableComputation}
Verifiable computation is motivated by the ability to compute. There are two
cases we consider here; first the case where a service provider (say a cloud
computing center) desires (or needs) to provide proof that their computations
are correct, and second the case where an entity wishes to prove that they can
perform a computation without having to reveal their data.

Verifying computation can be a necessary step for cloud computing companies. A
company willing to run computations on your data is worthless if the
computations are incorrect. However, verifiers (in this case the data providers)
are at an impasse, because to verify computations they must know the correct
answer.  Previous work has only been able to provide proof systems for specific
functions~\cite{sion2005query}, or rely on secure
hardware~\cite{anati2013innovative} or be inefficient due to relying of
homomorphic encryption~\cite{gentry2009fully}. 

Pinocchio~\cite{parno2013pinocchio} attempts to solve this by verifying
computation relying only on cryptographic assumptions, and while maintaining a
constant proof size. This is achieved by constructing proofs in 3 parts: ($G$,
$P$, $V$). $G$ is the key generator, which generates a public evaluation key and
a public verification key. The goal is to encode an arbitrary function $F$ into
a circuit $C$ whose results can be easily verified. 

The computer can then evaluate the function $F$ at input $x$ to obtain $F(x)= y$
and use this value along with the public evaluation key to produce a proof
$\pi_y$. The verifier can take this proof and use pairings (bilinear functions
satisfying $e(x^a,y^b) = e(x,y^{ab})$) to verify the computation is correct. The
key here is that the bilinear functions are quick to compute, and can be used to
verify that the exponents from the proof are used in the correct places.

However, this system still only allows for very restricted computations, limited
to computations of the form of fixed sized matrix multiplication.

Other work~\cite{ben2013snarks} provide proofs over a language defined over a
small ISA (\texttt{TinyRAM}) which allows for C programs to be compiled into a
verifiable ISA computation.

Zerocoin~\cite{miers2013zerocoin} provides a usable implementation of proofs in
zero knowledge, which we introduce briefly here. It is often desireable to be
able to proof knowledge to others, e.g., that an individual does posses the
private key of a public/private key pair. However, the simple method of proof
(i.e., simply producing the private key) is undesirable because voids the
usefulness of that value. The motivates zero knowledge proofs, allowing for an
individual to prove they have knowledge of a certain value without others
learning the value. In the example above such a proof might be for others to
encrypt values to the public key and require the individual to decrypt them.

Zerocoin provides a first step towards implementing zero knowledge proofs
towards Bitcoin. Bitcoin~\cite{nakamoto2008bitcoin} provides a decentralized
currency providing users with pseudo-nomity, but not anonymity. Zerocoin
introduces a method of proof to allow payments anonymously. As opposed to the
Bitcoin model where clients provide a wallet address that contains the requisite
funds to make a purchase, Zerocoin enables clients to provide a proof that one
of a list of deposits was done by the client, and that deposit has not been
spent before.

This proof is achieved using accumulators. An accumulator is simply a known base
value, raised to numerous exponents, the accumulator $A$ defined from  $u$ and
$C$ would be the value $u^{c_1\cdot c_2\cdots c_m} \mod N$ for all $c_i\in C$. A
witness to a value in an accumulator is an accumulator of all values except the
given one. For example, a witness for $c_1$ in the above would be the
accumulator $u^{c_2\cdots c_m}\mod N$, this provide a simple (but not zero
knowledge) way to prove a value is in an accumulator, simply provide an
accumulator, a value, and a witness. To turn this knowledgeable proof into a
zero knowledge proof, Zerocoin leverages the work of \cite{camenisch2002dynamic}
which provides a zero knowledge proof system using accumulators, as above the
proof relies on the prover providing their secrets obscured using RSA encryption
techniques, while the verifier can confirm that only a user with the necessary
secret knowledge could compute these attestation values with non-negligible
probability.